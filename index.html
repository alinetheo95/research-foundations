<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <link rel="stylesheet" href="style.css" />
</head>
<body>
  <main class="container">
    <section class="image-section">
      <img src="anatomy-ai-system.png" alt="Anatomy of an AI system diagram">
    </section>
    
    <header class="title-section">
      <h1>Anatomy of an AI System</h1>
    </header>

    <section class="intro-text">
      <p>
        <b>Data</b>
      </p>
    </section>

    <section class="details">
      <div class="left-column">
        <p><strong>Published</strong><br>2018</p>
        <p><strong>Written by</strong><br>Kate Crawford<br>Vladan Joler</p>
        <p><strong>Format</strong><br>Visual Infographic / Essay</p>
        <p><strong>Audience</strong><br>AI & Amazon Alexa Users / General Public</p>
      </div>
      <div class="right-column">
        <p><strong>Bibliography (by Author)</strong></p>
        <p><b>Crawford, K.</b> (2018, September 9). <i>Anatomy of AI: Unboxing the black box of Amazon Echo.</i></p>
        <p>The Verge Interview by James Vincent</p>
        <p>Retrieved from https://www.theverge.com/2018/9/9/17832124/ai-artificial-intelligence-supply-chain-anatomy-of-ai-kate-crawford-interview</p>
        <br>
        <b>Crawford, K.</b> (2021, April). <i>Atlas of AI and the Anatomy of an AI System</i>[Video]
        USC Annenberg School for Communication and Journalism
        Retrieved from https://www.youtube.com/watch?v=uM7gqPnmDDc
        <br>
        <br>
        <b>Crawford, K.</b> (2019). <i>Kate Crawford: Anatomy of AI</i> [Video lecture]
        UNSW Centre for Ideas / YouTube
        Retrieved from https://www.youtube.com/watch?v=i_EZwV6wGP0
        <br>
        <br>
        <p><strong>Bibliography (by Others)</strong></p>
        <p><b>Moltzau, A. </b>(2020, April 6). <i>Revisiting the Anatomy of An AI System</i></p>
        <p>Medium</p>
        <p>Retrieved from https://alexmoltzau.medium.com/revisiting-the-anatomy-of-an-ai-system-7b35abf10386</p>
        <br>
        <p><b>Aliza M.</b>(2018, November 26). <i>Anatomy of an AI System" by Crawford and Joler — A Response</i></p>
        <p>Medium</p>
        <p>Retrieved from https://medium.com/%40kimy566/anatomy-of-an-ai-system-edef7633bdd8</p>
        <br>
        <p><b>Kim, Y.</b>(2021, October 4). Reading response #03: Anatomy of an AI System</p>
        <p>Medium</p>
        <p>Retrieved from https://medium.com/%40kimy566/anatomy-of-an-ai-system-edef7633bdd8</p>
        <br>
        <p><b>Graute, U.</b>(n.d.). <i>Anatomy of an AI System</i></p>
        <p>LinkedIn</p>
        <p>Retrieved from https://www.linkedin.com/pulse/anatomy-ai-system-ulrich-graute-toxbf</p>
      </div>
    </section>

    <section class="details">
      <div class="analysis-content">
        <div class="analysis-image">
          <img src="Human.png">
        </div>
        <div class="analysis-text">
          <p><i>“But in this fleeting moment of interaction, a vast matrix of capacities is invoked: interlaced chains of resource extraction, human labor, and algorithmic processing across networks of mining, logistics, distribution, processing, prediction, and optimization.”</i></p>
        </div>
      </div>
    </section>

    <section class="intro-text2">
      <p><b>Analysis</b></p>
    </section>

    <div class="analysis-content reverse">
        <div class="analysis-image">
          <img src="Fractal Triangle.png" alt="Amazon Echo Dot schematics showing circular technical diagrams">
        </div>
        <div class="analysis-text">
          <p><i>Anatomy of an AI System</i> illustrates the relationship between the human and the machine as evolving technology and capitalism feed on convenience based consumerism and the impact this has on the earth and the labor exploitation of the workers involved in the process. The figure to the right demonstrates the complexity of extraction and production– each triangle representing a step of production and exploitation that contains previous phases.</p>
      </div>
      </div>
    </section>

    <section class="intro-text2">
      <p><b>Visual Representation</b></p>
    </section>

    <section class="details">
      <div class="analysis-content">
        <div class="analysis-image">
          <img src="Earth.png">
        </div>
        <div class="analysis-text">
          <p>The text is based primarily on a visual representation of the authors’ understanding of the lifecycle of a single AI system. Although they argue it can be too complex to comprehend, they break down the diagram into parts, explaining the different sections along the way. Reading the map from left to right tells the story of the Earth, directly relating to the story of the human that can be read from top to bottom. </p>
        </div>
      </div>
    </section>

    <section class="intro-text2">
      <p><b>Components</b></p>
    </section>

    <div class="analysis-content reverse">
        <div class="analysis-image">
          <img src="Alexa diagram.png" alt="Amazon Echo Dot schematics showing circular technical diagrams">
        </div>
        <div class="analysis-text">
          <p>Crawford and Jolen present us with an “exploded view of a planetary system across three stages of birth, life, and death” while analyzing a single AI system broken down into 21 parts. They focus on the Amazon Alexa, using it as a representation of the human-AI interaction and the complex nature of the relationship between the two. They hone in on the environmental damage of the process of producing and using AI systems, with Lithium extraction as the core example. The depletion of renewable resources that goes into making a human’s life more convenient is extremely damaging, but the authors make the argument that humans are also being exploited in the form of data labor by training these AI systems without intentionally consenting or knowing so.</p>
        </div>
      </div>
    </section>

    <section class="intro-text2">
      <p><b>Historical</b></p>
    </section>

    <section class="details">
      <div class="analysis-content">
        <div class="analysis-image">
          <img src="Extractivism.png">
        </div>
        <div class="analysis-text">
          <p>While the time period that Crawford and Jolen focus on is more or less current day (2018), the text brings in many historical references to support the analysis of the life cycle of an AI product. They introduce the concept of deep time, involving the Earth’s core and the mining that has taken place over generations. They consider three central processes required to run an artificial intelligence unit: material resources, human labor, and data that they consider across time, analyzing the lifespan of an Amazon Echo Unit at a planetary scale. The exploitation of labor is at the central focus of their investigation, as they argue this has been repeated throughout history. Digital labor, which leads to new accumulations of wealth and power, is concentrated to a small percentage of the population. The audience the authors are trying to reach is the general population, and people who interact with AI, which is just about everyone in the developed world, all of which are subject to digital labor. At the same time, they are targeting an audience who is also contributing to convenient consumerism, without knowledge that they are being used to train and optimize these AI systems. The authors state that the implications of AI is an ongoing timeline, and will be more significant than we can conceptualize at this point in time.</p>
        </div>
      </div>
    </section>

    <section class="intro-text2">
      <p><b>Methodology</b></p>
    </section>

    <div class="analysis-content reverse">
        <div class="analysis-text">
          <p>The software approach used in Anatomy of an AI can be classified as AI Stack deconstruction, in dissecting an Amazon Alexa as a node of a larger system of software, services, and machine learning operations through exploring Alexa’s voice service, speech recognition, feedback loops, and training data. It also highlights the black box problem, analyzing issues of secrecy and opaqueness in proprietary systems. Crawford and Jolen use human data as fuel, saying that humans are sources of unpaid digital labor in training these systems, and the issues of the hidden AI labor economy. The place of origin is the birthplace of the Alexa. They look at this process at a planetary scale, so their place of origin as well as their ending process is the Earth. Specifically, they start by analyzing lithium mining. One of the theoretical methods used is the Marxist Political theory, specifically Marx’s triangle of production, a figure in which they include in the diagram with product of labor (subject-object) at the top, with labor power (subject) and means of production (object) at the two bottom nodes of the triangle. Building off of Marxism, they also refer to Christian Fuchs’ digital labor theory when talking about labor and data extraction in the AI industry, saying that “digital labor is far from ephemeral or virtual, but is deeply embodied in different activities,” which contributes to their overall argument of the underlying labor and damaging ecological processes that go into producing a single AI system. </p>
        </div>
      </div>
    </section>

    <section class="intro-text2">
      <p><b>Author's Wider Practice</b></p>
    </section>

    <div class="analysis-content reverse">
        <div class="analysis-text">
          <p>Kate Crawford is also known for her book <i>Atlas of an AI</i>, which explores the same concepts of the ecological and sociopolitical effects the AI process has on the Earth and society. She speaks of the consequences of lithium mining for rechargeable batteries, community displacement in the locations that the mining occurs, and the inequality of the computation industry. She has also done interviews and presentations on her investigations into the AI process. In her presentation for UNSW Centre for Ideas, she speaks in depth about the misclassification of data sorting and how people are feeding racial and classist bias to AI systems. Her exploration into AI systems flourished when she was working at Microsoft in the research department at the time that machine learning took off. In evaluating her overall practice, she is calling on AI companies to be more transparent and honest about how these technologies are sourced and produced, and she is calling for collective action. In the interview portion of the UNSW presentation, she related climate change to the AI industry in the way that large companies account for 74% of contribution to climate change, stating that the same goes for AI production. She asks that people question where we actually need AI and where it’s being used merely for convenience. She is spreading knowledge about AI systems previously unknown to the public, advocating for peoples’ rights and more transparent processes as we move forward in the age of AI.</p>
        </div>
      </div>
    </section>

    <div class="image-container">
      <img src="workflows diagram.png" alt="Image 1">
      <img src="relational diagram.png" alt="Image 2">
    </div>

    <section class="intro-text2">
      <p><b>Assessment</b></p>
    </section>

    <div class="analysis-content reverse">
      <div class="analysis-text">
          <p>Crawford provides insightful analysis into the process of AI systems. I respect the research she has done and the audiences she has reached in raising awareness of the harms that can go into producing and using AI. Although, I have to recognize the fact that she is only asking questions, not providing answers. Her role is to initiate the questions, so that other people can take action- take action to enforce big tech companies to have more regulations and transparency and take action on thinking of ways AI can be used for good. I believe we need people like Crawford to initiate the conversations around this topic to enable other people to build off of her work and to start providing answers and solutions to her questions. She is also offering a lot of data to form her opinion that AI is “bad”- bad for the environment, bad for people who are involved in the process of mineral extraction, and bad for the general population because AI is constantly undergoing machine-learning and learning based on our (human) input, in which she calls free data labor. I again appreciate the research that has been done in order to initiate this question of where AI fits into society and to inform people of the unethical parts about the process. However, in investigating her research, I would argue that a lot of the issues she raises are not necessarily an issue of AI, but an issue of human nature, and the way that greed and power have formed the AI industry to be used for unjust and corrupt reasons, which can now be more widespread through AI. Through my investigation of Crawford’s work, I declare it as a starting point, and an insight into what AI can do. Now my question is how can AI be used for good? I want to reframe the question to explore how AI’s vast capacities, which Crawford critiques, can also be harnessed for environmental repair and sustainable infrastructure. What if we reframed how we see data labor and assumed that instead of training these systems for consumerism and profits for the 1%, we trained these systems to perform work that can help mitigate climate change? This is only the starting point to discover what AI can really do, and I do agree with Crawford in the fact that this is a pivotal point, and what we do in the coming future will have an immense impact. </p>
        </div>
      </div>
    </section>

    <section class="image-section">
      <img src="precedent pin up diagram 2.png" alt="Anatomy of an AI system diagram">
    </section>

    

    <footer class="footer">
    </footer>
  </main>
  <script src="main.js"></script>
</body>
</html>